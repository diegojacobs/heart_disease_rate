Divided the interval in half.

109 - 310 = low
311 - 512 = high

1. Naive Bayes 

 precision    recall  f1-score   support

          0       0.72      1.00      0.83       755
          1       0.67      0.01      0.01       301

avg / total       0.70      0.72      0.60      1056


2. Linear SVC

   precision    recall  f1-score   support

          0       0.82      0.95      0.88       755
          1       0.79      0.50      0.61       301

avg / total       0.81      0.82      0.80      1056


3. Logistic Regression

  precision    recall  f1-score   support

          0       0.91      0.80      0.85       755
          1       0.62      0.79      0.69       301

avg / total       0.82      0.80      0.81      1056


4. Decision Tree

    precision    recall  f1-score   support

          0       0.87      0.86      0.87       755
          1       0.67      0.68      0.68       301

avg / total       0.81      0.81      0.81      1056


5. Random Forest

  precision    recall  f1-score   support

          0       0.89      0.93      0.91       755
          1       0.80      0.70      0.75       301

avg / total       0.86      0.87      0.86      1056


6. Neural Network - Perceptron

precision    recall  f1-score   support

          0       0.87      0.89      0.88       755
          1       0.70      0.66      0.68       301

avg / total       0.82      0.82      0.82      1056


